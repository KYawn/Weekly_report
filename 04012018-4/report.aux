\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\citation{shokri2015privacy}
\citation{shokri2015privacy}
\citation{shokri2015privacy}
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\contentsline {section}{\numberline {1}引言}{1}{section.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces 传统中心化学习和去中心化学习对比\relax }}{1}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:learningApproaches}{{1}{1}{传统中心化学习和去中心化学习对比\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {传统的中心化学习}}}{1}{subfigure.1.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {去中心化学习}}}{1}{subfigure.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces 联合学习流程图:A 根据手机的使用情况，对本地模型进行个性化设置并训练上传模型更新；B 许多用户的模型更新被聚集在一起；C 优化共享模型，然后很多用户又对新的模型进行下载、训练，并重复这个过程。\relax }}{2}{figure.caption.2}}
\newlabel{fig:Google}{{2}{2}{联合学习流程图:A 根据手机的使用情况，对本地模型进行个性化设置并训练上传模型更新；B 许多用户的模型更新被聚集在一起；C 优化共享模型，然后很多用户又对新的模型进行下载、训练，并重复这个过程。\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}相关工作}{2}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}基于差分隐私的协作学习}{2}{subsection.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces 在MNIST数据集上，对CNN网络的含有差分隐私的协作学习。其中横轴为$\epsilon $，表示差分隐私的强度$\epsilon $越大差分隐私保护添加的噪声越弱。N表示参与者的人数，$\theta _d$表示参数下载的比例，$\theta _u$表示参数上传到比例。从图中可以看出，1：条件相同时参与人数越多准确性越高；2：$\epsilon $越大（噪声越小）准确性越高；3：$\theta _u$越大准确性越高。\relax }}{2}{figure.caption.3}}
\newlabel{fig:CCS15}{{3}{2}{在MNIST数据集上，对CNN网络的含有差分隐私的协作学习。其中横轴为$\epsilon $，表示差分隐私的强度$\epsilon $越大差分隐私保护添加的噪声越弱。N表示参与者的人数，$\theta _d$表示参数下载的比例，$\theta _u$表示参数上传到比例。从图中可以看出，1：条件相同时参与人数越多准确性越高；2：$\epsilon $越大（噪声越小）准确性越高；3：$\theta _u$越大准确性越高。\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {参与者为30人}}}{2}{subfigure.3.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {参与者为90人}}}{2}{subfigure.3.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {参与者为150人}}}{2}{subfigure.3.3}}
\citation{Phong2017PrivacyPreservingDL}
\citation{shokri2015privacy}
\citation{shokri2015privacy}
\citation{Phong2017PrivacyPreservingDL}
\citation{shokri2015privacy}
\citation{Phong2017PrivacyPreservingDL}
\citation{hitaj2017deep}
\citation{hitaj2017deep}
\citation{shokri2015privacy}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}基于同态加密的协作学习}{3}{subsection.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces 使用同态加密的协作学习模型\relax }}{3}{figure.caption.4}}
\newlabel{fig:TIFS17}{{4}{3}{使用同态加密的协作学习模型\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}对协作学习模型的攻击}{3}{subsection.2.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}介绍}{3}{subsubsection.2.3.1}}
\citation{hitaj2017deep}
\citation{shokri2015privacy}
\citation{bonawitz2017practical}
\citation{bonawitz2017practical}
\citation{hitaj2017deep}
\citation{shokri2015privacy}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}威胁模型}{4}{subsubsection.2.3.2}}
\bibstyle{IEEEtran}
\bibdata{references}
\bibcite{shokri2015privacy}{1}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces 使用GAN攻击正在训练MNIST数据集的协作深度学习模型。\relax }}{5}{figure.caption.5}}
\newlabel{fig:ganscenario}{{5}{5}{使用GAN攻击正在训练MNIST数据集的协作深度学习模型。\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}实验结果}{5}{subsubsection.2.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces 使用GAN在MNIST数据集上攻击两个参与者场景下的结果。图中下面一行是GAN生成的样本，上面一行是受害者训练集中的数据。\relax }}{5}{figure.caption.6}}
\newlabel{fig:ganresults}{{6}{5}{使用GAN在MNIST数据集上攻击两个参与者场景下的结果。图中下面一行是GAN生成的样本，上面一行是受害者训练集中的数据。\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$\theta _u = 1, \theta _d = 1$}}}{5}{subfigure.6.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$\theta _u = 0.1, \theta _d = 1$}}}{5}{subfigure.6.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {$\theta _u = 0.1, \theta _d = 0.1$}}}{5}{subfigure.6.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces 使用GAN在AT\&T的Olivetti人脸数据集上攻击的结果。诚实的参与者们互相独立地训练模型，且敌手$A$并没有本地的训练数据，通过使用GAN攻击，$A$可以重新构建出受害者$V$的训练数据。即使在使用差分隐私的情况下，这种攻击也能成功。\relax }}{5}{figure.caption.7}}
\newlabel{fig:41_participants}{{7}{5}{使用GAN在AT\&T的Olivetti人脸数据集上攻击的结果。诚实的参与者们互相独立地训练模型，且敌手$A$并没有本地的训练数据，通过使用GAN攻击，$A$可以重新构建出受害者$V$的训练数据。即使在使用差分隐私的情况下，这种攻击也能成功。\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}想法及未来工作}{5}{section.3}}
\bibcite{Phong2017PrivacyPreservingDL}{2}
\bibcite{hitaj2017deep}{3}
\bibcite{bonawitz2017practical}{4}
